import sys
import time
from pathlib import Path
import pandas as pd
import numpy as np
import xgboost as xgb
import lightgbm as lgb
import mlflow
import hydra
import pickle
import shutil
import pprint
import warnings
from typing import List, Tuple, Dict, Any
from omegaconf.dictconfig import DictConfig
from sklearn.metrics import roc_auc_score
from src.util.get_environment import get_exec_env, get_datadir, is_gpu, is_ipykernel
from src.util.fast_fillna import fast_fillna
from src.models.PurgedGroupTimeSeriesSplit import PurgedGroupTimeSeriesSplit
from src.util.calc_utility_score import utility_score_pd
warnings.filterwarnings("ignore")


def create_janeapi() -> Tuple[Any, Any]:
    DATA_DIR = get_datadir()
    if get_exec_env() not in ['kaggle-Interactive', 'kaggle-Batch']:
        sys.path.append(f'{DATA_DIR}/001')
    import janestreet
    env = janestreet.make_env()  # initialize the environment
    iter_test = env.iter_test()  # an iterator which loops over the test set
    return env, iter_test


def predict_fillna_forward(models: List[Any], features: List[str], target: str, OUT_DIR: str) -> None:
    '''
    Using high-performance nan forward-filling logic by Yirun Zhang
    Note: Be aware of the performance in the 'for' loop!
    Prediction API generates 1*130 DataFrame per iteration.
    Which means you need to process every record separately. (no vectorization)
    If the performance in 'for' loop is poor, it'll result in submission timeout.
    '''
    env, iter_test = create_janeapi()
    print('Start predicting')
    time_start = time.time()
    tmp = np.zeros(len(features))  # this np.ndarray will contain last seen values for features
    for (test_df, sample_prediction_df) in iter_test:  # iter_test generates test_df(1,130)
        x_tt = test_df.loc[:, features].values  # this is (1,130) ndarray([[values...]])
        x_tt[0, :] = fast_fillna(x_tt[0, :], tmp)  # use values in tmp to replace nan
        tmp = x_tt[0, :]  # save last seen values to tmp
        y_pred: np.ndarray = 0.
        for model in models:
            y_pred += model.predict(x_tt) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    shutil.move('submission.csv', f'{OUT_DIR}/submission.csv')


def predict_fillna_999(models: List[Any], features: List[str], target: str, OUT_DIR: str) -> None:
    env, iter_test = create_janeapi()

    print('Start predicting')
    time_start = time.time()
    for (test_df, sample_prediction_df) in iter_test:
        X_test = test_df.loc[:, features]
        X_test.fillna(-999)

        y_pred: np.ndarray = 0.
        for model in models:
            y_pred += model.predict(X_test.values) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    file = f'{OUT_DIR}/submission.csv'
    shutil.move('submission.csv', file)
    mlflow.log_artifact(file)

    return None


def get_model(model_name: str, model_param: Dict) -> Any:
    if model_name == 'XGBClassifier':
        return xgb.XGBClassifier(**model_param)
    elif model_name == 'LGBMClassifier':
        return lgb.LGBMClassifier(**model_param)
    else:
        raise ValueError(f'Invalid model_name: {model_name}')


def train_gbdt(
        train: pd.DataFrame,
        features: List[str],
        target: str,
        model_name: str,
        model_param: Dict,
        OUT_DIR: str
        ) -> None:

    print('Start training')

    X_train = train.loc[:, features].values
    y_train = train.loc[:, target].values
    model = get_model(model_name, model_param)
    model.fit(X_train, y_train)

    file = f'{OUT_DIR}/model_0.pkl'
    pickle.dump(model, open(file, 'wb'))
    mlflow.log_artifact(file)
    print('End training')

    return None


def train_gbdt_cv(
        train: pd.DataFrame,
        features: List[str],
        target: str,
        model_name: str,
        model_param: Dict,
        cv_param: Dict,
        OUT_DIR: str
        ) -> None:

    kf = PurgedGroupTimeSeriesSplit(**cv_param)
    scores = []
    for fold, (tr, te) in enumerate(kf.split(train.loc[target].values, train[target].values, train['date'].values)):
        pprint.pprint(f'Starting Fold {fold}:')
        X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values
        y_tr, y_val = train.loc[tr, target].values, train.loc[te, target].values
        model = get_model(model_name, model_param)
        model.fit(X_tr, y_tr,
                  eval_metric='logloss',
                  eval_set=[(X_tr, y_tr), (X_val, y_val)])
        val_pred = model.predict(X_val)
        auc = roc_auc_score(y_val, val_pred)

        date = train.loc[te, 'date'].values
        weight = train.loc[te, 'weight'].values
        resp = train.loc[te, 'resp'].values
        action = train.loc[te, 'action'].values
        utility_val = utility_score_pd(date, weight, resp, action)
        utility_pred = utility_score_pd(date, weight, resp, val_pred)

        score = {'fold': fold, 'auc': auc, 'utility_val': utility_val, 'utility_pred': utility_pred}

        mlflow.log_metrics(score)
        scores.append(score)
        print(score)

        file = f'{OUT_DIR}/model_{fold}.pkl'
        pickle.dump(model, open(file, 'wb'))
        mlflow.log_artifact(file)
        del model, val_pred, X_tr, X_val, y_tr, y_val, date, weight, resp, action, utility_val, utility_pred

        return None


@hydra.main(config_path="../conf/ex005", config_name="config")
def main(cfg: DictConfig) -> None:
    print(type(cfg))
    print(cfg)
    DATA_DIR = get_datadir()

    # follow these sequences: uri > experiment > run > others
    tracking_uri = f'{DATA_DIR}/mlruns'
    mlflow.set_tracking_uri(tracking_uri)  # uri must be set before set_experiment
    mlflow.set_experiment(cfg.mlflow.experiment.name)
    mlflow.start_run()
    mlflow.set_tags(cfg.mlflow.experiment.tags)
    if not is_ipykernel():
        mlflow.log_artifacts('.hydra/')

    mlflow.log_param('feature_engineering', cfg.feature_engineering)
    mlflow.log_param('cv.name', cfg.cv.name)
    mlflow.log_params(cfg.cv.param)
    mlflow.log_params(cfg.model.param)
    mlflow.log_param('feature', cfg.features)

    OUT_DIR = f'{DATA_DIR}/{cfg.EXNO}'
    Path(OUT_DIR).mkdir(exist_ok=True)
    if is_gpu():  # check if you're utilizing gpu if present
        assert cfg.model.param.tree_method == 'gpu_hist'

    # FE
    train = pd.DataFrame()

    # load feature
    features = []
    for f in cfg.features:
        df = pd.read_pickle(f'{DATA_DIR}/{f.path}').loc[:, f.cols]
        train = pd.concat([train, df], axis=1)
        features += f.cols
        print(f'Feature: {f.name}, shape: {df.shape}')

    # load target
    df = pd.read_pickle(f'{DATA_DIR}/{cfg.target.path}').loc[:, cfg.target.col]
    train = pd.concat([train, df], axis=1)

    print(f'Input train shape: {train.shape}')

    # Fill missing values
    if cfg.feature_engineering.method_fillna == '-999':
        train.loc[:, features] = train.loc[:, features].fillna(-999)
    elif cfg.feature_engineering.method_fillna == 'forward':
        train.loc[:, features] = train.loc[:, features].fillna(method='ffill').fillna(0)

    # Train
    if cfg.option.train:
        if cfg.cv.name == 'nocv':
            train_gbdt(train, features, cfg.target.col, cfg.model.name, cfg.model.param, OUT_DIR)
        elif cfg.cv.name == 'PurgedGroupTimeSeriesSplit':
            train_gbdt_cv(train, features, cfg.target.col, cfg.model.name, cfg.model.param, cfg.cv.param, OUT_DIR)
        else:
            raise ValueError(f'Invalid cv: {cfg.cv}')

    # Predict
    if cfg.option.predict:
        models = []
        for i in range(cfg.cv.param.n_splits):
            model = pd.read_pickle(open(f'{OUT_DIR}/model_{i}.pkl', 'rb'))
            models.append(model)

        if cfg.feature_engineering.method_fillna == '-999':
            predict_fillna_999(models, features, cfg.target.col, OUT_DIR)
        elif cfg.feature_engineering.method_fillna == 'forward':
            predict_fillna_forward(models, features, cfg.target.col, OUT_DIR)
        else:
            raise ValueError(f'Invalid method_fillna: {cfg.feature_engineering.method_fillna}')

    return None


if __name__ == '__main__':
    main()
