import os
import sys
import time
from pathlib import Path
import pandas as pd
import numpy as np
import xgboost as xgb
import mlflow
import hydra
import pickle
import shutil
import pprint
import warnings
from sklearn.metrics import roc_auc_score
from src.util.get_environment import get_exec_env, is_gpu
from src.util.fast_fillna import fast_fillna
from src.models.PurgedGroupTimeSeriesSplit import PurgedGroupTimeSeriesSplit
from src.util.calc_utility_score import utility_score_pd
warnings.filterwarnings("ignore")


def get_original_cwd() -> str:
    '''
    Returns original working directory for execution.
    In CLI, hydra changes cwd to outputs/xxx.
    In Jupyter Notebook, hydra doesn't change cwd.
    This is due to that you need to initialize & compose hydra config using compose API in Jupyter.
    Under compose API, hydra.core.hydra_config.HydraConfig is not initialized.
    Thus, in Jupyter Notebook, you need to avoid calling hydra.utils.get_original_cwd().
    Refer:
    https://github.com/facebookresearch/hydra/issues/828
    https://github.com/facebookresearch/hydra/blob/master/hydra/core/hydra_config.py
    https://github.com/facebookresearch/hydra/blob/master/hydra/utils.py
    '''
    if hydra.core.hydra_config.HydraConfig.initialized():
        return hydra.utils.get_original_cwd()
    else:
        return os.getcwd()


def create_janeapi() -> (object, object):
    DATA_DIR = get_original_cwd() + '/data'
    if get_exec_env() not in ['kaggle-Interactive', 'kaggle-Batch']:
        sys.path.append(f'{DATA_DIR}/001')
    import janestreet
    env = janestreet.make_env()  # initialize the environment
    iter_test = env.iter_test()  # an iterator which loops over the test set
    return env, iter_test


def predict_fillna_forward(models: list, features: list, target: str, OUT_DIR: str) -> None:
    '''
    Using high-performance nan forward-filling logic by Yirun Zhang
    Note: Be aware of the performance in the 'for' loop!
    Prediction API generates 1*130 DataFrame per iteration.
    Which means you need to process every record separately. (no vectorization)
    If the performance in 'for' loop is poor, it'll result in submission timeout.
    '''
    env, iter_test = create_janeapi()
    print('Start predicting')
    time_start = time.time()
    tmp = np.zeros(len(features))  # this np.ndarray will contain last seen values for features
    for (test_df, sample_prediction_df) in iter_test:  # iter_test generates test_df(1,130)
        x_tt = test_df.loc[:, features].values  # this is (1,130) ndarray([[values...]])
        x_tt[0, :] = fast_fillna(x_tt[0, :], tmp)  # use values in tmp to replace nan
        tmp = x_tt[0, :]  # save last seen values to tmp
        y_pred = 0.
        for model in models:
            y_pred += model.predict(x_tt) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    shutil.move('submission.csv', f'{OUT_DIR}/submission.csv')


def predict_fillna_999(models: list, features: list, target: str, OUT_DIR: str) -> None:
    env, iter_test = create_janeapi()

    print('Start predicting')
    time_start = time.time()
    for (test_df, sample_prediction_df) in iter_test:
        X_test = test_df.loc[:, features]
        X_test.fillna(-999)

        y_pred = 0.
        for model in models:
            y_pred += model.predict(X_test.values) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    file = f'{OUT_DIR}/submission.csv'
    shutil.move('submission.csv', file)
    mlflow.log_artifact(file)


def train_xgb(train: pd.DataFrame, features: list, target: str, model_param: dict, OUT_DIR: str) -> None:
    print('Start training')

    X_train = train.loc[:, features].values
    y_train = train.loc[:, target].values
    model = xgb.XGBClassifier(**model_param)
    model.fit(X_train, y_train)

    file = f'{OUT_DIR}/model_0.pkl'
    pickle.dump(model, open(file, 'wb'))
    mlflow.log_artifact(file)
    print('End training')


def train_xgb_cv(train: pd.DataFrame, features: list, target: str, model_param: dict, cv_param: dict, OUT_DIR: str) -> None:
    kf = PurgedGroupTimeSeriesSplit(**cv_param)
    scores = []
    for fold, (tr, te) in enumerate(kf.split(train.loc[target].values, train[target].values, train['date'].values)):
        pprint(f'Starting Fold {fold}:')
        X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values
        y_tr, y_val = train.loc[tr, target].values, train.loc[te, target].values
        model = xgb.XGBClassifier(**model_param)
        model.fit(X_tr, y_tr,
                  eval_metric='logloss',
                  eval_set=[(X_tr, y_tr), (X_val, y_val)])
        val_pred = model.predict(X_val)
        auc = roc_auc_score(y_val, val_pred)

        date = train.loc[te, 'date'].values
        weight = train.loc[te, 'weight'].values
        resp = train.loc[te, 'resp'].values
        action = train.loc[te, 'action'].values
        utility_val = utility_score_pd(date, weight, resp, action)
        utility_pred = utility_score_pd(date, weight, resp, val_pred)

        score = {'fold': fold, 'auc': auc, 'utility_val': utility_val, 'utility_pred': utility_pred}

        mlflow.log_metrics(score)
        scores.append(score)
        print(score)

        file = f'{OUT_DIR}/model_{fold}.pkl'
        pickle.dump(model, open(file, 'wb'))
        mlflow.log_artifact(file)
        del model, val_pred, X_tr, X_val, y_tr, y_val, date, weight, resp, action, utility_val, utility_pred


@hydra.main(config_path="../conf/ex005", config_name="config")
def main(cfg) -> None:
    print(cfg)
    DATA_DIR = get_original_cwd() + '/data'

    # follow these sequences: uri > experiment > run > others
    tracking_uri = f'{DATA_DIR}/mlruns'
    mlflow.set_tracking_uri(tracking_uri)  # uri must be set before set_experiment
    mlflow.set_experiment(cfg.mlflow.experiment.name)
    mlflow.start_run()
    mlflow.set_tags(cfg.mlflow.experiment.tags)

    mlflow.log_param('method_fillna', cfg.method_fillna)
    mlflow.log_param('cv.name', cfg.cv.name)
    mlflow.log_params(cfg.cv.param)
    mlflow.log_params(cfg.model.param)
    mlflow.log_param('features', cfg.features)

    OUT_DIR = f'{DATA_DIR}/{cfg.EXNO}'
    Path(OUT_DIR).mkdir(exist_ok=True)
    if is_gpu():  # check if you're utilizing gpu if present
        assert cfg.model.param.tree_method == 'gpu_hist'

    # FE
    train = pd.read_pickle(f'{DATA_DIR}/{cfg.in_files.train_in1}')
    print(f'Input train shape: {train.shape}')
    target = 'action'

    train = train.query('weight > 0').reset_index(drop=True)
    train[target] = (train['resp'] > 0).astype('int')

    # Fill missing values
    if cfg.method_fillna == '-999':
        # train[cfg.features] = train[cfg.features].fillna(-999)
        train.loc[:, cfg.features] = train.loc[:, cfg.features].fillna(-999)
    elif cfg.method_fillna == 'forward':
        train.loc[:, cfg.features] = train.loc[:, cfg.features].fillna(method='ffill').fillna(0)

    # Train
    if cfg.option.train:
        if cfg.cv.name == 'nocv':
            train_xgb(train, cfg.features, target, cfg.model.param, OUT_DIR)
        elif cfg.cv.name == 'PurgedGroupTimeSeriesSplit':
            train_xgb_cv(train, cfg.features, target, cfg.model.param, cfg.cv.param, OUT_DIR)
        else:
            raise ValueError(f'Invalid cv: {cfg.cv}')

    # Predict
    if cfg.option.predict:
        models = []
        for i in range(cfg.cv.param.n_splits):
            model = pd.read_pickle(open(f'{OUT_DIR}/model_{i}.pkl', 'rb'))
            models.append(model)

        if cfg.method_fillna == '-999':
            predict_fillna_999(models, list(cfg.features), target, OUT_DIR)
        elif cfg.method_fillna == 'forward':
            predict_fillna_forward(models, list(cfg.features), target, OUT_DIR)
        else:
            raise ValueError(f'Invalid method_fillna: {cfg.method_fillna}')


if __name__ == '__main__':
    main()
