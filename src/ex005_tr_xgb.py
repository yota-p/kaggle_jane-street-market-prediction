import os
import sys
import time
from pathlib import Path
import pandas as pd
import numpy as np
import xgboost as xgb
import mlflow
import hydra
import pickle
import shutil
import pprint
import warnings
from sklearn.metrics import roc_auc_score
from src.util.get_environment import get_exec_env, is_gpu
from src.util.fast_fillna import fast_fillna
from src.models.PurgedGroupTimeSeriesSplit import PurgedGroupTimeSeriesSplit
# from src.util.calc_utility_score import utility_score_pd
warnings.filterwarnings("ignore")


def create_janeapi():
    DATA_DIR = hydra.utils.get_original_cwd() + '/data'
    if get_exec_env() not in ['kaggle-Interactive', 'kaggle-Batch']:
        sys.path.append(f'{DATA_DIR}/001')
    import janestreet
    env = janestreet.make_env()  # initialize the environment
    iter_test = env.iter_test()  # an iterator which loops over the test set
    return env, iter_test


def predict_fillna_forward(models, features, target, OUT_DIR):
    '''
    Using high-performance nan forward-filling logic by Yirun Zhang
    Note: Be aware of the performance in the 'for' loop!
    Prediction API generates 1*130 DataFrame per iteration.
    Which means you need to process every record separately. (no vectorization)
    If the performance in 'for' loop is poor, it'll result in submission timeout.
    '''
    env, iter_test = create_janeapi()
    print('Start predicting')
    time_start = time.time()
    tmp = np.zeros(len(features))  # this np.ndarray will contain last seen values for features
    for (test_df, sample_prediction_df) in iter_test:  # iter_test generates test_df(1,130)
        x_tt = test_df.loc[:, features].values  # this is (1,130) ndarray([[values...]])
        x_tt[0, :] = fast_fillna(x_tt[0, :], tmp)  # use values in tmp to replace nan
        tmp = x_tt[0, :]  # save last seen values to tmp
        y_pred = 0.
        for model in models:
            y_pred += model.predict(x_tt) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    shutil.move('submission.csv', f'{OUT_DIR}/submission.csv')


def predict_fillna_999(models, features, target, OUT_DIR):
    env, iter_test = create_janeapi()

    print('Start predicting')
    time_start = time.time()
    for (test_df, sample_prediction_df) in iter_test:
        X_test = test_df.loc[:, features]
        X_test.fillna(-999)

        y_pred = 0.
        for model in models:
            y_pred += model.predict(X_test.values) / len(models)
        y_pred = y_pred > 0
        sample_prediction_df[target] = y_pred.astype(int)
        env.predict(sample_prediction_df)

    elapsed_time = time.time() - time_start
    test_len = 15219  # length of test data (for developing API)
    print('End predicting')
    print(f'Prediction time: {elapsed_time} s, Prediction speed: {test_len / elapsed_time} iter/s')

    # move submission file generated by env into experiment directory
    file = f'{OUT_DIR}/submission.csv'
    shutil.move('submission.csv', file)
    mlflow.log_artifact(file)


def train_xgb(train, features, target, XGB_PARAM, OUT_DIR):
    print('Start training')
    mlflow.log_params(XGB_PARAM)
    mlflow.log_param('features', features)

    X_train = train.loc[:, features].values
    y_train = train.loc[:, target].values
    model = xgb.XGBClassifier(**XGB_PARAM)
    model.fit(X_train, y_train)

    file = f'{OUT_DIR}/model_0.pkl'
    pickle.dump(model, open(file, 'wb'))
    mlflow.log_artifact(file)
    print('End training')


def train_xgb_cv(train, features, target, XGB_PARAM, n_splits, OUT_DIR):
    mlflow.log_params(XGB_PARAM)
    mlflow.log_param('features', features)
    mlflow.log_param('n_splits', n_splits)

    kf = PurgedGroupTimeSeriesSplit(
        n_splits=n_splits,
        max_train_group_size=150,
        group_gap=20,
        max_test_group_size=60
    )
    scores = []
    for fold, (tr, te) in enumerate(kf.split(train[target].values, train[target].values, train['date'].values)):
        pprint(f'Starting Fold {fold}:')
        X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values
        y_tr, y_val = train.loc[tr, target].values, train.loc[te, target].values
        model = xgb.XGBClassifier(**XGB_PARAM)
        model.fit(X_tr, y_tr,
                  eval_metric='logloss',
                  eval_set=[(X_tr, y_tr), (X_val, y_val)])
        val_pred = model.predict(X_val)
        auc = roc_auc_score(y_val, val_pred)

        '''
        date = train.loc[te, 'date'].values
        weight = train.loc[te, 'weight'].values
        resp = train.loc[te, 'resp'].values
        action = train.loc[te, 'action'].values
        utility_val = utility_score_pd(date, weight, resp, action)
        utility_pred = utility_score_pd(date, weight, resp, val_pred)
        record = pd.Series([fold, auc, utility_val, utility_pred], index=scores.columns)
        '''
        score = {'fold': fold, 'auc': auc}
        scores.append(score)
        mlflow.log_metrics(score)
        # print(f'Fold {fold} auc: {auc}, utility_val: {utility_val}, utility_pred: {utility_pred}')
        # print(f'Fold {fold} auc: {auc}')

        file = f'{OUT_DIR}/model_{fold}.pkl'
        pickle.dump(model, open(file, 'wb'))
        mlflow.log_artifact(file)
        del model, val_pred, X_tr, X_val, y_tr, y_val


@hydra.main(config_path="conf/ex005", config_name="config")
def main(cfg) -> None:
    print(cfg)
    # Setup
    DATA_DIR = hydra.utils.get_original_cwd() + '/data'
    IN_DIR = f'{DATA_DIR}/002'
    XGB_PARAM = cfg.model.param
    if is_gpu():
        XGB_PARAM.update({'tree_method': 'gpu_hist'})

    tracking_uri = f'{DATA_DIR}/mlruns'
    experiment_name = 'ex005_tr_xgb'
    if cfg.option.small:
        experiment_name += '_small'
    mlflow.set_tracking_uri(tracking_uri)
    mlflow.set_experiment(experiment_name)
    mlflow.start_run()
    mlflow.log_param('is_gpu', is_gpu())

    assert(os.path.exists(IN_DIR))
    OUT_DIR = f'{DATA_DIR}/{cfg.EXNO}'
    Path(OUT_DIR).mkdir(exist_ok=True)

    # FE
    train = pd.read_pickle(f'{IN_DIR}/train.pkl')
    print(f'Input train shape: {train.shape}')
    target = 'action'
    features = [c for c in train.columns if 'feature' in c]

    train = train.query('weight > 0').reset_index(drop=True)
    train[target] = (train['resp'] > 0).astype('int')

    # Fill missing values
    mlflow.log_param('method_fillna', cfg.method_fillna)
    if cfg.method_fillna == '-999':
        train[features] = train[features].fillna(-999)
    elif cfg.method_fillna == 'forward':
        train[features] = train[features].fillna(method='ffill').fillna(0)

    # Train
    if cfg.option.train:
        mlflow.log_param('cvStrategy', cfg.cvStrategy)
        if cfg.cvStrategy.name is None:
            train_xgb(train, features, target, XGB_PARAM, OUT_DIR)
        elif cfg.cvStrategy.name == 'PurgedGroupTimeSeriesSplit':
            train_xgb_cv(train, features, target, XGB_PARAM, cfg.cvStrategy.n_splits, OUT_DIR)
        else:
            raise ValueError(f'Invalid cvStrategy: {cfg.cvStrategy}')

    file = f'{OUT_DIR}/model_0.pkl'
    mlflow.log_artifact(file)

    # Predict
    if cfg.cvStrategy.name is None:
        n_models = 1
    else:
        n_models = cfg.cvStragety.n_splits

    if cfg.option.predict:
        models = []
        for i in range(n_models):
            model = pd.read_pickle(open(f'{OUT_DIR}/model_{i}.pkl', 'rb'))
            models.append(model)

        if cfg.method_fillna == '-999':
            predict_fillna_999(models, features, target, OUT_DIR)
        elif cfg.method_fillna == 'forward':
            predict_fillna_forward(models, features, target, OUT_DIR)
        else:
            raise ValueError(f'Invalid method_fillna: {cfg.method_fillna}')


if __name__ == '__main__':
    main()
